\chapter{Research Methodology} \label{chp:method}

In this chapter the methodology used to develop random forest model will be discussed. The details of fusion between AIS data, ECMWF and CMEMS data source used for training the model will be presented in \Cref{sec:data_acquisition}. Suitable methodology application during data pre-processing will be described in \Cref{sec:data_prep}. The selection for appropriate, domain knowledge based, feature selection will be explained in \Cref{sec:feature_select}. The selection of the most optimal model hyperparameter for different tree-based model will be explained in \Cref{sec:hpo}. Different performance metrics is used to validate the model's generalisation capability, The underlying principle of the metrics is elaborated in \Cref{sec:perf_metrics}. Summary of methodology application in this study is summarised in \Cref{sec:methodology_application} and visually represented in figure \Cref{fig:flowchart}. 

\begin{figure}[h]
    \centering
        \includegraphics[width=\textwidth]{02_figures/flowmethod2.png}
        \caption{Scheme of proposed methodology}
        \label{fig:flowchart}
\end{figure}

\section{Data Acquisition}\label{sec:data_acquisition}

For the purpose of model training, 2021 AIS data from Ro-Ro ferry ship Hammershus is collected. The shore-based AIS data is made available by Danish Maritime Authority which tracked her journey between ports of K{\o}ge, R{\o}nne, Ystad and Sassnitz and structured according to \Cref{tbl:AIS_struct}. The AIS data is fused with weather data from ECMWF\footnote{European Centre for Medium-Range Weather Forecast} with temporal resolution of 1 hour at granularity of 0.25° (longitude) x 0.25° (latitude), data from ECMWF provides information for wind, waves and seawater temperature. The information for current is obtained from CMEMS\footnote{Copernicus Marine Environment Monitoring Service} with temporal resolution of 3 hours at granularity of  0.25° (longitude) x 0.25° (latitude).\\ 

The resulting fusion resulted in dataset with temporal resolution of 1 hour. Some information static information from the AIS data which only indicated the ship's identity are excluded. This includes ship's MMSI, Callsign, Name, IMO and Navigational Status. Additionally, information of the ship's Rate of Turn (ROT) is not available in this case. The weather information is synchronised so that the wind, waves, seawater temperature and sea current belongs to the same weather grid with same temporal resolutions.\\ 

The features \begin{enumerate*}[label={(\arabic*)}]
    \item wind direction,
    \item swell direction,
    \item and wind wave direction
\end{enumerate*} are oriented to true north. However, to reflect the actual direction of weather effects that are acting on the ship, these features are converted to true direction; where true direction is defined as the direction of weather effect with respect to the bow of the ship. The value ranges between 0° and 180°. Subsequently, through vector decomposition, the northward and eastward wind velocity is converted to absolute wind speed and wind direction \emph{with respect to True North},$\varphi$:

\begin{equation}\label{eqn:vwindabs}
    V_{\text{wind}} = \sqrt{(V_{\text{wind}}^N)^2 + (V_{\text{wind}}^E)^2} 
\end{equation}
\begin{equation}\label{eqn:winddir}
    \varphi = 
    \begin{cases}
        360 - \arctan(\frac{V_{\text{wind}}^E}{V_{\text{wind}}^N}) \quad \text{\textbf{if}} \quad V_{\text{wind}}^E > 0 \quad \wedge \quad V_{\text{wind}}^N < 0 \\ 
        180 - \arctan(\frac{V_{\text{wind}}^E}{V_{\text{wind}}^N}) \quad \text{\textbf{if}} \quad V_{\text{wind}}^E < 0 \quad \wedge \quad V_{\text{wind}}^N > 0 \\ 
        270 - \arctan(\frac{V_{\text{wind}}^E}{V_{\text{wind}}^N}) \quad \text{\textbf{if}} \quad V_{\text{wind}}^E > 0 \quad \wedge \quad V_{\text{wind}}^N > 0 \\
        \arctan(\frac{V_{\text{wind}}^E}{V_{\text{wind}}^N}) \qquad \text{\textbf{otherwise}} 
    \end{cases}   
\end{equation}

Similarly, information of Northward and Eastward current Velocity is converted to absolute current speed and current direction \emph{with respect to True North} $\gamma$.\\ 

\begin{equation}\label{eqn:vcurrabs}
    V_{\text{current}} = \sqrt{(V_{\text{current}}^N)^2 + (V_{\text{current}}^E)^2} 
\end{equation}
\begin{equation}\label{eqn:currdir}
    \gamma = 
    \begin{cases}
        360 - \arctan(\frac{V_{\text{current}}^E}{V_{\text{current}}^N}) \quad \text{\textbf{if}} \quad V_{\text{current}}^E < 0 \quad \wedge \quad V_{\text{current}}^N > 0 \\ 
        180 - \arctan(\frac{V_{\text{current}}^E}{V_{\text{current}}^N}) \quad \text{\textbf{if}} \quad V_{\text{current}}^E > 0 \quad \wedge \quad V_{\text{current}}^N < 0 \\ 
        270 - \arctan(\frac{V_{\text{current}}^E}{V_{\text{current}}^N}) \quad \text{\textbf{if}} \quad V_{\text{current}}^E < 0 \quad \wedge \quad V_{\text{current}}^N < 0 \\
        \arctan(\frac{V_{\text{current}}^E}{V_{\text{current}}^N}) \qquad \text{\textbf{otherwise}} 
    \end{cases}   
\end{equation}

This conversion is performed as the information of current speed and current direction, $\gamma$, is necessary to perform the correction formula shown in \Cref{eqn:stwx} and \Cref{eqn:stwy}. However, for training purpose, this feature will not be considered. Instead, the true current direction and true wind direction will be considered. The initial structure have 27 features, 9 AIS features and 18 weather features. The structure of the initial dataset i.e. before data preprocessing and feature selection, is summarised in \Cref{tbl:dataset_init_struct} \\

\begin{table}
    \footnotesize
    \centering
    % \resizebox {\textwidth}{!}
    {\begin{tabular}{ p{0.4\textwidth} c }
    \hline
    \textbf{Feature} & \textbf{Feature Name}  \\
    \hline
    \multicolumn{2}{l}{\textbf{AIS data}}\\
    \hline
    Position Time Stamp [DD\slash MM\slash YYYY HH:MM:SS] & {\tt Time} \\
    Latitude [°] & {\tt LAT}   \\
    Longitude [°] & {\tt LON}  \\
    Width [m] & {\tt width}  \\
    Length [m] & {\tt length}\\
    SOG [Knots] & {\tt sog} \\
    COG [m/s] & {\tt cog}  \\
    Heading [°] & {\tt heading}  \\
    Draught [m] & {\tt draught} \\
    \hline
    \multicolumn{2}{l}{\textbf{Weather Data (0.5° Granularity)}}\\
    \hline
    Wind Speed [m/s] & {\tt windspeed} \\
    True North Wind Direction, $\varphi$ [°] & {\tt truenorthcurrentdir} \\
    Air Temperature Above Oceans [K] & {\tt oceantemperature} \\
    % Air Density Above Oceans [$\text{kg/m}^3$]& - \\
    Maximum Wave Height [m] & {\tt waveheight} \\
    % Swell Direction [°] & - \\
    % Wind Wave Direction & - \\
    Swell Period [s] & {\tt swellperiod} \\
    Wind Wave Period [s] & {\tt windwaveperiod}\\
    % Wave Direction [°] & - \\
    Wave Period [s] & {\tt waveperiod}\\
    Sea Surface Temperature [K] & {\tt surftemp}\\
    Combined Wind Wave Swell Height [m] &  {\tt windwaveswellheight} \\
    Swell Height [m] & {\tt swellheight}\\
    Wind Wave Height [m] & {\tt windwaveheight}  \\
    % Surface Pressure & - \\
    Current Speed [m/s] & {\tt curspeed} \\
    True North Current Direction $\gamma$ [°] & {\tt truenorthcurrentdir}\\
    True Wind Direction [°] & {\tt truewinddir}  \\
    True Current Direction [°] & {\tt truecurrentdir} \\
    True Swell Direction [°] & {\tt trueswelldir} \\
    True Wind Wave Direction [°] & {\tt truewindwavedir} \\
    True Wave Direction [°] & {\tt truewavedir} \\
    \end{tabular}}
\caption{Structure of fused dataset}\label{tbl:dataset_init_struct}
\end{table}

\section{Data Preprocessing}\label{sec:data_prep}

This section presents the steps taken to during data preprocessing. The dataset will be first subjected to data cleaning which include identification of anomalies and missing values, the steps are explained in \Cref{sec:data_cleaning}. Boundary condition is then applied to ensure that the model represent operating condition at steady state. Using domain knowledge, appropriate features are selected and discarded to ensure the model obeys shipping domain knowledge. This dataset is to be split into training, validation and test dataset. These steps will be further elaborated in \Cref{sec:feature_select}.

\subsection{Data Cleaning}\label{sec:data_cleaning}

The journey between the port of K{\o}ge, R{\o}nne, Ystad and Sassnitz is plotted using {\tt QGIS}\footnote{https://qgis.org/en/site/, {\tt QGIS} is a free and open source geographic information system}. The plot of the journey is shown in \Cref{fig:YearJourney}, it can be seen, that the journey between R{\o}nne and Sassnitz is not represented completely. As in this information is missing due to poor coverage in the area between Sassnitz and R{\o}nne. This is shown by the plot shown in \Cref{fig:aiscoverage}. Therefore, the data plot for the journey between Sassnitz and R{\o}nne will be excluded. Basic threshold of decimal degrees of 55.04° N for latitude is applied, this threshold will exclude the journey between Sassnitz and R{\o}nne.\\ 
\begin{figure}
    \centering
        \includegraphics[width=0.9\textwidth]{02_figures/AIS_Coverage.png}
        \caption{Shore based AIS Coverage based on data from AIS database \cite{webaisdk.2023}}
        \label{fig:aiscoverage}
\end{figure}

In its initial state, the dataset contains 7453 data points which described the journey of the ship in one year. The initial data points represented all navigational status of the ship, which include ``mooring'', ``anchoring'' and ``underway using engine''. This is clearly observed in the histogram for the SOG distribution in figure BLALA. To ensure that the dataset represents the actual operating condition of ship in steady state, a threshold of 5 knots is applied. SOG can vary due to changing sea state, but it can also be reduced by the ship's operator around the port when it departs from port of origin or arriving at port of arrival. Any data points with SOG less than 5 knots will be discarded which is considered as manoeuvring \cite{Abebe.2020}. After applying the SOG threshold, the amount of data points significantly decrease from 7453 data points to 3506 data points. This indicated that about half of the total data points represented the ship's stationary behaviour. \\
\begin{figure}
    \centering
        \includegraphics[width=0.8\textwidth]{02_figures/SassnitznoFilter.png}
        \caption{Journey of the ship in a year}
        \label{fig:YearJourney}
\end{figure}

From preliminary analysis, possible source of error is identified for data points representing current speed. In range of current speed between $0.01$ and $0.03$ [m/s], noticeable peak in data points is observed. This peak attributed to missing information on northward and eastward current speed in some data points from the provided dataset. This resulted in single random error value for current speed which resulted in the peak observed in the histogram.\\ 

To address the missing values, the missing values for eastward current and northward current are imputed using {\tt KNNImputer} feature from \scikit/. Each sample's missing values are imputed using the mean of nearest neighbour found in training dataset \cite{FabianPedregosa.2011}. Once the missing values of northward and southward current are imputed, the current speed for the missing values will be recalculated.\\ 

The imputing approach using k-nearest neighbour is also applied to other weather features that contained missing values i.e. {\tt NaN} values. Imputing missing values is necessary as modelling package by \scikit/ cannot handle missing values. Imputing strategy using k-nearest neighbour is considered as it should reflect the weather conditions within the region of missing values.\\

\subsection{Feature Selection}\label{sec:feature_select}

To select appropriate features for the model, correlation between the features is first studied. Feature selection is necessary to simplify the model and subsequently save computing cost during training. Selection of features is based on statistical approach of High Correlation Filter proposed by Abebe et al. \cite{Abebe.2020}. This approach considers pairs of features with correlation features higher than 0.7 as one entity. However, the selection of highly correlated features must not violate natural state of matter. Therefore, in addition to statistical approach, the scientific reasoning behind the correlations will be considered and prioritised over the statistical approach.\\

From AIS data, the information on \begin{enumerate*}[label={(\arabic*)}]
    \item time,
    \item latitude,
    \item longitude,
    \item width, and
    \item length
\end{enumerate*} are not included for training. As time, latitude and longitude have no impact on the ship. While the width and length is properties from the ship that remain constant.\\  

The features \begin{enumerate*}[label={(\arabic*)}]
\item combined wind wave swell height, 
\item swell height, maximum wave height 
\item and wind wave height \end{enumerate*} are physically correlated. In sea wave theory, wind wave swell height is also known as significant wave height $H_{1/3}$. It is defined as the mean of the highest one-third of waves in the wave record \cite{Holthuijsen.2007}. \\

\begin{figure}
    \centering
        \includegraphics[width=.85\textwidth]{02_figures/Bretschneider_1965_wavedist.jpg}
        \caption{Statistical distribution of wave heights \cite{bretschneider.1965}}
        \label{fig:wavestats}
\end{figure}

The distribution of wave heights can be represented by probability density function. Hence, the term ``highest one-third of waves'' here means the region of wave heights that belong in the upper one-third of a probability density function, this is illustrated in \Cref{fig:wavestats}. From this distribution, the relation between significant wave height $H_{1/3}$, the highest ten percent of waves $H_{10}$ and average wave height $\overline{H}$ can be summarised as follows \cite{bretschneider.1965,Holthuijsen.2007}: 

\begin{equation}\label{eqn:Hsig_mean}
    \overline{H} = 0.625\cdot H_{1/3}
\end{equation}
\begin{equation}\label{eqn:Hsig_Hten}
    H_{10} = 2.03\cdot \overline{H} = 1.27\cdot H_{1/3} 
\end{equation}
\begin{equation}\label{eqn:Hsig_max}
    H_{\text{max}} = 2 \cdot H_{1/3} 
\end{equation} 

Additionally, Bitner-Gregersen \cite{BitnerGregersen.2005} described the relation between the significant wave height, wind wave height and swell height through following equation:

\begin{equation}\label{eqn:H_sig_root}
    H_{1/3} = \sqrt{(H_{\text{swell}})^2 + (H_{\text{windwave}})^2} 
\end{equation}

From here, it is clear that significant wave height should be retained for modelling, as it holds critical information regarding wave properties. The features swell height, wind wave height and maximum wave height will be dropped as it can be defined through correlations defined in \Cref{eqn:Hsig_mean},\Cref{eqn:Hsig_Hten},\Cref{eqn:Hsig_max} and \Cref{eqn:H_sig_root}. This decision is also statistically supported through the high correlation filter method. As shown in \Cref{fig:heatmap1}, high correlation are observed between these features.\\

\begin{figure}
    \centering
    \includegraphics[width=.9\linewidth,height=.9\textheight,keepaspectratio]{02_figures/heatmap_corr_ovr.png}
    \caption{Correlation Heat Map}
    \label{fig:heatmap_ovr}
\end{figure}

From \Cref{fig:heatmap1}, high correlation is observed between wave period, swell period and wind wave period. Bitner-Gregersen further elaborated that the state of the sea can be described through the significant height $H_{1/3}$ and spectral peak $T_p$ with help of Torsethaugen peak \cite{K.Torsethaugen.2004}. Hence, the features swell period and wind wave period are discarded as it only distinguish whether the sea is dominated by swell or by wind. The feature wave period will still be retained. Consequently, the features true wind wave direction and true swell direction will be discarded as the features that explained the magnitude of these features are discarded.\\

Statistically, the heading and COG are highly correlated, but both features are retained as it explain two different parameters of the ship. Course Over Ground reflects the ship course heading while heading represented the actual heading of the ship at a particular point of time. Same principle also apply between air temperature above ocean and sea surface temperature. Air temperature above oceans represents the temperature of wind while sea surface temperature represents current temperature of current.\\

From feature selection, 5 features from AIS data are discarded while 11 features are removed from the weather data. To predict the ship speed, The SOG will be selected as the label to train the model. The remaining attributes will be selected as training features. This is summarised in \Cref{tbl:dataset_train_struct}.
\begin{table}
    % \small
    \centering
    % \resizebox {\textwidth}{!}
    {\begin{tabular}{ |p{8cm}|c| }
    \hline
    \multicolumn{2}{|l|}{\textbf{Training Label}}\\
    \hline
    SOG [Knots] & {\tt sog} \\
    \hline
    \multicolumn{2}{|l|}{\textbf{Training Features}}\\
    \hline
    COG [m/s] & {\tt cog}  \\
    \hline
    Heading [°] & {\tt heading}  \\
    \hline
    Draught [m] & {\tt draught} \\
    \hline
    Wind Speed [m/s] & {\tt windspeed} \\
    \hline
    Air Temperature Above Oceans [K] & {\tt oceantemperature} \\
    \hline
    Maximum Wave Height [m] & {\tt waveheight} \\
    \hline
    Wave Period [s] & {\tt waveperiod}\\
    \hline
    Sea Surface Temperature [K] & {\tt surftemp}\\
    \hline
    Combined Wind Wave Swell Height [m] &  {\tt windwaveswellheight} \\
    \hline
    Current Speed [m/s] & {\tt curspeed} \\
    \hline
    True Wind Direction [°] & {\tt truewinddir}  \\
    \hline
    True Current Direction [°] & {\tt truecurrentdir} \\
    \hline
    True Wave Direction [°] & {\tt truewavedir} \\
    \hline
    \end{tabular}}
\caption{Structure of fused dataset}\label{tbl:dataset_train_struct}
\end{table}

\section{Modelling}\label{sec:modelling}

In this section, the modelling of ship speed through SOG using selected features will be performed using tree-based regressor model. The tree-based regressor model considered are decision tree regressor, random forest regressor and extra-tree regressor. In addition, the tree-based models are compared against multiple linear regressor to as benchmark. The methodology to develop the best model is divided into several steps.\\

For training, the dataset is split into training, validation and test dataset in ratio of 73:18:9. Journey data from the month of June is arbitrarily selected as test dataset. The remaining dataset will be split into training and validation dataset in 80:20 ratio. The explanation of training process and selection of the best model is broken down into several sections. In \Cref{sec:hpo}, the tuning parameter of \scikit/ will be studied extensively as suitable tuning could result in improved model performance.\\

Appropriate statistical performance measures are applied to each model; the performance measures selected will help to evaluate how well a model is able to make generalisation on validation and test dataset. The evaluation will be cross validated in form of k-folding. The details on evaluation methodology used in this thesis will be discussed in \Cref{sec:perf_metrics}. \\

\subsection{Performance Metrics for Validation}\label{sec:perf_metrics}

To gain sensible estimate of model performance and how precise a model is, the model will be cross validated by means of k-folding. K-fold cross validation split the training set into k subsets which is called \emph{folds}, then the model will be trained k times using k-1 subsets and remaining one for validation, this process is illustrated in \Cref{fig:kfold}. For each iteration, each model is evaluated using different performance metrics such as \begin{enumerate*}[label={(\arabic*)}]
    \item  Coefficient of Determination ($R^2$), 
    \item Explained Variance (EV), 
    \item Mean Absolute Error (MAE),
    \item Root Mean Square (RMSE) and
    \item Median Absolute Deviation (MAD). 
\end{enumerate*} The results from each iteration is then averaged, where the information on model precision can be gained from the standard deviation. Performing k-fold cross validation checks model robustness against different datasets. The properties of each performance metric will be discussed in the following sections.

\begin{figure}
    \centering
    \includegraphics[width=.85\textwidth]{02_figures/kfold.png}
    \caption{Visual illustration of k-folding, Grey shaded box represents the validation data while white box represents the training data}
    \label{fig:kfold}
\end{figure}

\subsubsection*{Coefficient of Determination ({$R^2$})}\label{sec:rsquared}

The coefficient of determination $R^2$ gives a measure on prediction quality, $R^2$ quantifies the ability of the regression model to approximate the actual values. $R^2 $ is defined by \Cref{eqn:rsquared}, where $y$ represents true target output, $\hat{y}$ represents the predictor output and $\overline{y}$ represents the mean. $R^2$ score range between 0 and 1, higher values i.e. $R^2 \rightarrow 1$ indicate better model fit and score of 1 indicate perfect prediction.\\

\begin{equation}\label{eqn:rsquared}
    R^2(y,\hat{y}) = 1 - \frac{\sum_{i = 1}^{n} (y_{\text{i}} - \hat{y}_{\text{i}} )^2 }{\sum_{i = 1}^{n} (y_{\text{i}} - \overline{y}_{\text{i}})^2} \quad \textbf{where} \quad \overline{y} = \frac{1}{n}\sum_{1}^{n} y_\text{i}
\end{equation}

\subsubsection*{Explained Variance (EV)}\label{sec:expVar}

Explained variance indicate how well a model can capture variance from a dataset. It is defined by \Cref{eqn:expVar}, where $\sigma_x$ represents standard deviation of parameter $x$. EV score range between 0 and 1, where the best score of $EV = 1$ can be obtained if $\sigma^2_{(y-\hat{y})} \rightarrow 0$.\\  

\begin{equation}\label{eqn:expVar}
    EV(y,\hat{y}) = 1 - \frac{\sigma^2_{(y-\hat{y})}}{\sigma^2_{y}}
\end{equation}

\subsubsection*{Mean Absolute Error (MAE)}\label{sec:MAE}

MAE indicated the expected value of absolute ($L^1$ norm) error, and it can be calculated by:

\begin{equation}\label{eqn:MAE}
    MAE(y,\hat{y}) = \frac{1}{n}\sum_{i=1}^{n} |y_{\text{i}} - \hat{y}_{\text{i}}| 
\end{equation}

\subsubsection*{Root Mean Square Error (RMSE)}\label{sec:RMSE}

The RMSE describe the expected value of quadratic error. RMSE place large penalty on large deviation between true and estimated values and for this reason, it can be used to as a metric to indicate model performance against outliers. Ideal score is observed when $\text{RMSE} \rightarrow 0$. RMSE can be considered as absolute measure of model fitness. Omitting the root term, RMSE becomes MSE, which is the loss function of \Cref{eqn:costfun} that is used to determine the most optimal split in a regression decision tree.\\

\begin{equation}\label{eqn:RMSE}
    RMSE(y,\hat{y}) = \sqrt{\frac{1}{n}\sum_{i=1}^{n} (y_{\text{i}} - \hat{y}_{\text{i}})^2} 
\end{equation}

\subsubsection*{Median Absolute Deviation (MAD)}\label{sec:MAD} 

MAD is a performance metrics that considers the median of the absolute errors. It is robust to outlier as it only consider median performance

\begin{equation}\label{eqn:MAD}
    MAD(y,\hat{y}) =  \text{median} (|y_{\text{1}} - \hat{y}_{\text{1}}|,\dots,|y_{\text{i}} - \hat{y}_{\text{i}}|)
\end{equation}


\subsection{Model Hyperparameter Optimisation}\label{sec:hpo}

The subject of parameter tuning was briefly discussed in \Cref{sec:dt_theo}. In \Cref{sec:dt_theo} parameter tuning was applied to decision tree regressor to avoid overfitting by changing the minimum amount of samples a leaf node has. This example implies that altering model hyperparameter will affect the model performance. However, the optimisation of the hyperparameter cannot be performed \emph{a priori} and as such iterative process will be performed until best hyperparameter value is found.\\ 

\begin{table}[ht]
    \scriptsize
    \centering
    % \resizebox {\textwidth}{!}
    {\begin{tabular}{ p{0.33\textwidth}p{3cm}p{3cm}p{3cm}  }
    \hline
    \multicolumn{1}{c}{\textbf{Model}} & \multicolumn{1}{c}{\textbf{Decision Tree}}  & \multicolumn{1}{c} {\textbf{Random Forest}} & \multicolumn{1}{c}{\textbf{Extra-Trees}}\\
    \hline
    Number of trees & \multicolumn{1}{c}{1} & \multicolumn{1}{c}{Many} & \multicolumn{1}{c}{Many}\\
    Features considered for split at each node &   \multicolumn{1}{c}{All features}  & \multicolumn{1}{c}{Random subset of features} & \multicolumn{1}{c}{Random subset of features} \\
    Bootstrapping & \multicolumn{1}{c}{Not applied} & \multicolumn{1}{c}{Yes} & \multicolumn{1}{c}{No}\\
    Split Rule  & \multicolumn{1}{c}{Best split} & \multicolumn{1}{c}{Best split}& \multicolumn{1}{c}{Random split}\\
    \end{tabular}}
\caption{Comparison of tree based model from \Cref{sec:tree_intro}}\label{tbl:table_trees}
\end{table}

\scikit/ offers {\tt GridSearchCV} and {\tt RandomizedSearchCV} to help search for the most optimal hyperparameter. Both solutions operate with similar principle: The selected hyperparameters to be tuned with its value range is evaluated using cross validation to evaluate the best possible combination between the selected hyperparameters. The difference between {\tt GridSearchCV} and {\tt RandomizedSearchCV} lies in how it searches for the best value for the selected hyperparameters: {\tt GridSearchCV} involves construction of grids containing all possible combinations of hyperparameter value in specified range.{\tt RandomizedSearchCV} randomly samples hyperparameter values.\\ 

The exhaustive nature of {\tt GridSearchCV} means that it is computationally costly to perform, especially when there are multiple hyperparameters to be considered and value search space is large. {\tt RandomizedSearchCV} gives more control to computing budget by setting the number of iteration and usually produces more accurate results than {\tt GridSearchCV} approach. \cite{Geron.2019,J.Bergstra.2012}. \\

For this reason, the {\tt RandomizedSearchCV} will be employed to search for best possible hyperparameter. However, the limitation of \emph{a priori} knowledge of hyperparameter value still exists. In spite of {\tt RandomizedSearchCV} ability to control the computational budget, it is still takes considerable time to obtain the best hyperparameter value. The computational budget may be spent on searches in unpromising search space. With that, initial exploration on the effect of each hyperparameter on model performance will be performed to give better overview on which search space that should be considered during hyperparameter optimisation. In the next subsections, the effect of tunable hyperparameter of tree-based model from \scikit/ will be explored to give baseline numbers for the search space. RMSE is used as performance metrics as the hyperparameter parameter optimisation done in this thesis aims to reduce the error during prediction. \\ 

\subsubsection{Number of features}\label{sec:max_features}

Defined with default value as {\tt max\_features=None} in \scikit/. This hyperparameter controls the number of features to be considered when looking for the best split, the default {\tt None} option means it will consider all features. This parameter tuning is available for Decision Tree Regressor, Random Forest Regressor and Extra-Tree Regressor. Initial exploration indicated Random Forest Regressor and Extra Tree Regressor benefit from considering more features, Decision Tree Regressor requires further fine-tuning to optimise the model as the default {\tt None} means it will consider all features when searching for best split.\\ 

\begin{figure}[h]
    \centering
        \includegraphics[width=.85\textwidth]{02_figures/hpo_n_features.png}
        \caption{Hyperparameter tuning of {\tt max\_features}}
        \label{fig:hpo_n_features}
\end{figure}

\subsubsection{Number of sample in a leaf node}\label{sec:min_samples_leaf}

Defined with default value as {\tt min\_samples\_leaf=1} in \scikit/. This parameter controls number of samples required to be at leaf node, where split point will be considered if the leaf contains at least {\tt min\_samples\_leaf=n} training samples in each left and right branch. As shown in \Cref{fig:geron6_6}, tuning this hyperparameter to higher values helps to smoothen the model and avoid overfitting. However, this may lead to underfitting as the model is unable to capture the trend within the data. This is supported by the findings shown in \Cref{fig:hpo_min_samples_leaf}, the DTR benefits from regularisation at certain breakeven point, in this case, it is found to be at {\tt min\_samples\_leaf=4}. But after this breakeven point, the model's performance degrades. It is also observed that RFR and ETR does not benefit from any form of regularisation.  

\begin{figure}[h]
    \centering
        \includegraphics[width=.85\textwidth]{02_figures/hpo_min_samples_leaf.png}
        \caption{Hyperparameter tuning of {\tt min\_samples\_leaf}}
        \label{fig:hpo_min_samples_leaf}
\end{figure}

\subsubsection{Depth of Tree}\label{sec:max_depth}

Defined with default value as {\tt max\_depth=None} in \scikit/. This hyperparameter controls the growth of the tree. Leaving it at {\tt max\_depth=None} means the tree will grow until all leaves are pure i.e. until minimum MSE is obtained or when the number of samples is less than the minimum number of samples required to split an internal node. Similar to {\tt min\_samples\_leaf}, DTR shows improvement until a certain breakeven point. RFR performance seems to stabilise at certain depth while ETR benefits from allowing full growth of the tree. The results are summarised in \Cref{fig:hpo_max_depth}  

\begin{figure}[h]
    \centering
        \includegraphics[width=.95\textwidth]{02_figures/hpo_max_depth.png}
        \caption{Hyperparameter tuning of {\tt max\_depth}}
        \label{fig:hpo_max_depth}
\end{figure}

\subsubsection{Number of Trees}\label{sec:n_estimators}

Defined with default value as {\tt n\_estimators=100}. This hyperparameter controls the amount of trees i.e. predictors in a forest. Tuning of number of trees will have an effect on the training time and it is only available to RFR and ETR. The default value seems to yield satisfactory result, as the performance for both RFR and ETR stabilise after in this case stabilise after 100 trees, as seen in \Cref{fig:hpo_n_features}. 

\begin{figure}[h]
    \centering
        \includegraphics[width=.95\textwidth]{02_figures/hpo_n_estimators.png}
        \caption{Hyperparameter tuning of {\tt n\_estimators}}
        \label{fig:n_estimators}
\end{figure}


\begin{figure}
    \centering
        \includegraphics[width=.85\textwidth]{02_figures/JuneFilter.png}
        \caption{Journey of the ship in June}
        \label{fig:JuneJourney}
\end{figure}

\subsection{Methodology Application}\label{sec:methodology_application}

As such, this thesis aims to find optimisation possibilities for the BBM to extract maximum prediction performance from tree-based model. The estimation of engine power using Holtrop-Mennen method involves a lot of The approximations. To ensure correctness during estimation of engine power, the approximations are based on   of ship dimensions and mechanical data are based  

\begin{itemize}
    \item Two data sources are imported. {\tt AIS\_weather\_H\_ok2\_copy.csv} \\ and {\tt AIS\_weather\_h\_rename\_copy.csv}. The information from the latter comma delimited 
    file will be used for calculating the ship Speed Through Water (STW).  
    The information required is the true north current direction. Which is obtained from the vector component of the Northward and Southward current.
    \item This dataframe will be merged with the main dataframe from \\ the file {\tt AIS\_weather\_H\_ok2\_copy.csv}.
    \item Omission of the journey data between Ronne and Sassnitz
    \item SOG threshold is applied to omit ship mooring and maneuvering to accurately represent the ship's steady state operation 
    \cite{Abebe.2020,BalBesikci.2016,Gkerekos.2019,Yang.2020}. This threshold is selected as 5 knots according to \cite{Abebe.2020}
    \item The AIS data from June is filtered. This data will be used as validation data to check the model's performance.
\end{itemize}
 
\subsection{Data Analysis}
\begin{itemize}
    \item The features are represented in a histogram plot. For the feature Current speed, anomaly is detected. Certain spike is detected around $0.01 - 0.03$ \verb|m/s|. Reasons unknown. The data is retained, including the spike, until a definitive answer can be found.
    \item OPEN QUESTION : What is the necessity of feature standardization / normalization ? Normalization is required for ANN as model training requires the value between 0 and 1. But in case of RFR, there is no such requirement. Through testing, data standardization also does not seem to improve the model's performance. 
\end{itemize}




\begin{sidewaysfigure}
    \includegraphics[width=\linewidth,height=\textheight,keepaspectratio]{02_figures/outputhist.png}
    \caption{Histogram of the features}
    \label{sidewaysfig:hist1}
\end{sidewaysfigure}

\newpage

\begin{itemize}
    \item The correlation of the features against SOG are determined. It is found that :
    \begin{itemize}
        \item Draught
        \item Course Over Ground (COG)
        \item heading
        \item Wind Speed
        \item Current Speed
        \item True Current direction
    \end{itemize}
    Have relatively stronger correlation to SOG compared to other features, albeit the correlation is a weak one
    \item The correlation between the features is displayed using the following the heat map. From the heat map it can be observed that between these features:
    \begin{itemize}
        \item Waveheight and wind wave swell height
        \item Waveheight and wind wave height
        \item Windwaveswellheight and wave period
    \end{itemize}
    Have a strong correlation between each other.  
    \item Open topic: 
    \begin{itemize}
        \item Feature reduction is possible, \cite{Abebe.2020} suggested high feature correlation filter, the filter suggest that two features which has a high correlation $(>90\%)$ is to be combined into a single feature. But the author is unsure whether this combination is physically sensible. Hence, this filter is yet to be applied for feature reduction. 
        \item Some of these features can be connected through wave equations, but the author has not found an equation which could relate these features.
    \end{itemize}
    \item The random forest regressor could not function when \verb|NaN| values are present. With that, the missing values are filled in using the {\tt imputer} function. The missing values are filled in by means of \verb|KNN|.
\end{itemize}

\newpage

\begin{figure}[h]
    \includegraphics[width=\linewidth,height=\textheight,keepaspectratio]{02_figures/heatmap_corr.png}
    \caption{Correlation Heat Map}
    \label{fig:heatmap1}
\end{figure}

\subsection{Modelling}

\begin{itemize}
    \item The data is split into 80:20 ratio. But considering the validation data, it is split into approximately 73:18:9.
    \item The model is then trained using Random Forest Regression (RFR). Additional training is also performed using Decision Tree Regressor (DTR). DTR model performance will be used as a benchmark as it is also a tree-based modelling method with similar methodology to RFR.
    \item The computational time of DTR is significantly faster than RFR
    Model Evaluation    
\end{itemize}

\subsection{Predicting STW}
\begin{itemize}
    \item The ship's Speed Through Water STW can be calculated using vector component of the SOG and current speed. The direction used will be according to True North. \cite{Yang.2020,Zhou.2020}
    \item SOG represents the speed of the ship with reference to the ground, while the STW represent the ship's speed with reference to water.
    \item SOG also can be termed by the ship's speed that is captured by the GPS, and does not consider any effect of the current
    \item This means that the ship's STW will be greater than the ship's SOG when there is current moving against the ship's movement direction and vice versa 
    \item The vector decomposition can be defined from the following equations, which is based on the equation by \cite{Yang.2020}:
    \begin{itemize}
        \item The ship's SOG $V_g$ can be decomposed into $V_{g}^x$ and $V_{g}^y$, which represents the $x$ and $y$ components of the SOG respectively using the ship's course heading (COG) $\beta$ \emph{with respect to True North}:
        \begin{equation}\label{eqvgx}
            V_{g}^x = V_g\sin(\beta)   
        \end{equation}
        \begin{equation}\label{eqvgy}
            V_{g}^y = V_g\cos(\beta)   
        \end{equation}
        \item To consider the effect of sea current. The current speed $V_c$ will also be decomposed to $x$ and $y$ components respectively using the current direction $\gamma$ \emph{with respect to True North}:
        \begin{equation}\label{eqvcx}
            V_{c}^x = V_g\sin(\gamma)   
        \end{equation}
        \begin{equation}\label{eqvcy}
            V_{c}^y = V_g\cos(\gamma)   
        \end{equation}
        \item from here the ship' STW $V_{wx}$ and $V_{wy}$ component can be found from the following equation: 
        \begin{equation}
            V_{w}^x = V_{g}^x - V_{c}^x    
        \end{equation}
        \begin{equation}
            V_{w}^y = V_{g}^y - V_{c}^y 
        \end{equation}
        \item The magnitude of the STW can be readily obtained from the following vector synthesis
        \begin{equation}
            V_w = \sqrt{(V_{w}^x)^2 + (V_{w}^y)^2} 
        \end{equation}
    \end{itemize}
    \newpage

    \item This principle is applied to the following Python script. \ref{eqvcx}

\begin{python}
       
        # Convert SOG from [Knots] to [m/s]
    
        dfprog["vgms"] = dfprog["sog_pred"]/1.9438
        
        # Convert the angles from [Degrees] to [Radians]

        rad_gamma = np.deg2rad(dfprog["gamma"])
        rad_cog = np.deg2rad(dfprog["cog"])

        # Decomposition in x-component

        dfprog["vgx"] = dfprog["vgms"] * np.sin(rad_cog)
        dfprog["vcx"] = dfprog["curspeed"] * np.sin(rad_gamma)
        dfprog["stw_x"] = (dfprog["vgx"] - dfprog["vcx"])

        # Decomposition in y-component

        dfprog["vgy"] = dfprog["vgms"] * np.cos(rad_cog)
        dfprog["vcy"] = dfprog["curspeed"] * np.cos(rad_gamma)
        dfprog["stw_y"] = (dfprog["vgy"] - dfprog["vcy"])

        # Vector synthesis and reconversion to [Knots] from [m/s]

        dfprog["vwms_p"] = np.sqrt(dfprog["stw_x"]**2 + dfprog["stw_y"]**2)
        dfprog["stw_pred"] = dfprog["vwms_p"]*1.9438  

    \end{python}
\newpage

\begin{sidewaysfigure}
    \includegraphics[width=\linewidth,height=\textheight,keepaspectratio]{02_figures/rfrftree.png}
    \caption{Correlation Heat Map}
    \label{fig:Random Forest Regression Tree}
\end{sidewaysfigure}


\end{itemize}

